from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import azure.cognitiveservices.speech as speechsdk
import os
import uuid
from fastapi.responses import FileResponse

app = FastAPI()

# Replace with your Azure subscription key and region
subscription_key = "YourAzureSubscriptionKey"
region = "YourAzureRegion"  # e.g., "eastus"

# Define the path to save the audio file (without UUID initially)
audio_folder = "static/audio/"

# Ensure the folder exists
if not os.path.exists(audio_folder):
    os.makedirs(audio_folder)

class TextRequest(BaseModel):
    text: str

@app.post('/synthesize-speech')
async def synthesize_speech(request: TextRequest):
    text = request.text

    if not text:
        raise HTTPException(status_code=400, detail="Text is required")

    # Generate a unique UUID for each file
    unique_filename = str(uuid.uuid4()) + ".wav"
    audio_file_path = os.path.join(audio_folder, unique_filename)

    # Initialize speech configuration with Azure subscription key and region
    speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=region)
    speech_config.speech_synthesis_voice_name = "en-US-JennyNeural"  # Choose voice

    # Set the audio output to the newly generated file name
    audio_config = speechsdk.audio.AudioOutputConfig(filename=audio_file_path)

    # Create a synthesizer object
    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)

    # Synthesize the text to speech
    result = synthesizer.speak_text_async(text).get()

    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        print("Successfully synthesized the speech.")
        # Return the URL to the audio file
        return {"audioUrl": f"/audio/{unique_filename}"}
    else:
        print("Speech synthesis failed:", result.error_details)
        raise HTTPException(status_code=500, detail="Speech synthesis failed")

# Serve the audio file statically
@app.get("/audio/{filename}")
async def serve_audio(filename: str):
    file_path = os.path.join(audio_folder, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path)
    else:
        raise HTTPException(status_code=404, detail="Audio file not found")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=5000)




from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import azure.cognitiveservices.speech as speechsdk
import os
import uuid
from fastapi.responses import FileResponse

app = FastAPI()

# Replace with your Azure subscription key and region
subscription_key = "YourAzureSubscriptionKey"
region = "YourAzureRegion"  # e.g., "eastus"

# Define the path to save the audio file (without UUID initially)
audio_folder = "static/audio/"

# Ensure the folder exists
if not os.path.exists(audio_folder):
    os.makedirs(audio_folder)

class TextRequest(BaseModel):
    text: str

@app.post('/synthesize-speech')
async def synthesize_speech(request: TextRequest):
    text = request.text

    if not text:
        raise HTTPException(status_code=400, detail="Text is required")

    # Generate a unique UUID for each file
    unique_filename = str(uuid.uuid4()) + ".wav"
    audio_file_path = os.path.join(audio_folder, unique_filename)

    # Initialize speech configuration with Azure subscription key and region
    speech_config = speechsdk.SpeechConfig(subscription=subscription_key, region=region)
    speech_config.speech_synthesis_voice_name = "en-US-JennyNeural"  # Choose voice

    # Set the audio output to the newly generated file name
    audio_config = speechsdk.audio.AudioOutputConfig(filename=audio_file_path)

    # Create a synthesizer object
    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)

    # Synthesize the text to speech
    result = synthesizer.speak_text_async(text).get()

    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        print("Successfully synthesized the speech.")
        # Return the URL to the audio file
        return {"audioUrl": f"/audio/{unique_filename}"}
    else:
        print("Speech synthesis failed:", result.error_details)
        raise HTTPException(status_code=500, detail="Speech synthesis failed")

# Serve the audio file statically
@app.get("/audio/{filename}")
async def serve_audio(filename: str):
    file_path = os.path.join(audio_folder, filename)
    if os.path.exists(file_path):
        return FileResponse(file_path)
    else:
        raise HTTPException(status_code=404, detail="Audio file not found")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=5000)

import { Component } from '@angular/core';
import { TextToSpeechService } from './text-to-speech.service';

@Component({
  selector: 'app-root',
  templateUrl: './app.component.html',
  styleUrls: ['./app.component.css'],
})
export class AppComponent {
  textToSpeak: string = '';
  audioUrl: string | null = null;

  constructor(private textToSpeechService: TextToSpeechService) {}

  // Method to synthesize speech and get the audio file URL
  synthesizeSpeech() {
    if (this.textToSpeak.trim()) {
      this.textToSpeechService.synthesizeSpeech(this.textToSpeak).subscribe(
        (response) => {
          this.audioUrl = response.audioUrl;
          this.playAudio();
        },
        (error) => {
          console.error('Error synthesizing speech:', error);
        }
      );
    } else {
      alert('Please enter text to synthesize.');
    }
  }

  // Method to play the audio once the URL is retrieved
  playAudio() {
    if (this.audioUrl) {
      const audio = new Audio(this.audioUrl);
      audio.play();
    }
  }
}


---------
import { Injectable } from '@angular/core';
import { HttpClient } from '@angular/common/http';
import { Observable } from 'rxjs';

@Injectable({
  providedIn: 'root',
})
export class TextToSpeechService {
  private baseUrl = 'http://localhost:33000'; // FastAPI server running on port 33000

  constructor(private http: HttpClient) {}

  // Method to synthesize speech and get the audio file URL
  synthesizeSpeech(text: string): Observable<any> {
    return this.http.post<any>(`${this.baseUrl}/synthesize-speech`, { text });
  }

  // Method to retrieve the audio file from the server
  getAudioFile(fileName: string): Observable<Blob> {
    return this.http.get(`${this.baseUrl}/audio/${fileName}`, {
      responseType: 'blob',  // Ensure the response is in blob format
    });
  }

  // Method to synthesize speech, get the file URL, and then fetch the file
  async synthesizeAndGetAudioFile(text: string): Promise<Blob> {
    try {
      // Synthesize speech
      const response = await this.synthesizeSpeech(text).toPromise();
      
      // Retrieve the audio file using the filename from the response
      const audioUrl = response.audioUrl;
      const fileName = audioUrl.split('/').pop();  // Extract the filename from the URL
      
      // Fetch the audio file
      return await this.getAudioFile(fileName!).toPromise();
    } catch (error) {
      throw new Error('Error while synthesizing or retrieving the audio file.');
    }
  }
}
---------
import { Component } from '@angular/core';
import { TextToSpeechService } from './text-to-speech.service';

@Component({
  selector: 'app-root',
  templateUrl: './app.component.html',
  styleUrls: ['./app.component.css'],
})
export class AppComponent {
  textToSpeak: string = '';
  audioUrl: string | null = null;

  constructor(private textToSpeechService: TextToSpeechService) {}

  // Method to synthesize speech and play the audio
  async synthesizeSpeech() {
    if (this.textToSpeak.trim()) {
      try {
        // Step 1: Synthesize the speech and get the audio file
        const audioBlob = await this.textToSpeechService.synthesizeAndGetAudioFile(this.textToSpeak);
        
        // Step 2: Create a URL for the audio blob
        const audioUrl = URL.createObjectURL(audioBlob);
        
        // Step 3: Play the audio
        this.playAudio(audioUrl);
      } catch (error) {
        console.error('Error synthesizing speech:', error);
      }
    } else {
      alert('Please enter text to synthesize.');
    }
  }

  // Method to play the audio
  playAudio(audioUrl: string) {
    const audio = new Audio(audioUrl);
    audio.play();
  }
}
